# MediBot â€“ AI-Powered Medical Chatbot using RAG

MediBot is an AI-driven chatbot designed to answer medical queries by retrieving relevant information from domain-specific documents using Retrievalâ€‘Augmented Generation (RAG). This project showcases the integration of vector databases, large language models (LLMs), and interactive UI components to solve real-world problems.

---

##  Features

- Retrievalâ€‘Augmented Generation pipeline using LangChain  
- Contextâ€‘aware Q&A using Mistralâ€‘7B or Groqâ€‘hosted LLaMA model  
- FAISSâ€‘powered vector search with HuggingFace embeddings  
- Realâ€‘time chat interface built with Streamlit  
- Modular architecture for future enhancements  

---

##  Tech Stack

| Component      | Tool/Library                                |
|----------------|----------------------------------------------|
| Language Model | Mistralâ€‘7B via HuggingFace / LLaMA via Groq  |
| Framework      | LangChain                                    |
| Embeddings     | HuggingFace (MiniLMâ€‘L6â€‘v2)                   |
| Vector DB      | FAISS                                        |
| UI             | Streamlit                                    |
| Language       | Python                                       |
| Hosting        | AWS EC2 (optional)                           |

---

##  Project Structure

```bash
.
â”œâ”€â”€ create_memory_for_llm.py       # Ingest PDFs and generate vector embeddings
â”œâ”€â”€ connect_memory_with_llm.py     # Set up RetrievalQA with LLM and FAISS
â”œâ”€â”€ medibot.py                     # Streamlit chatbot interface
â”œâ”€â”€ data/                          # Input PDFs
â”œâ”€â”€ vectorstore/                   # FAISS vector database
â”œâ”€â”€ Pipfile / Pipfile.lock         # Pipenv environment files
â”œâ”€â”€ requirements.txt               # Alternative install file
â”œâ”€â”€ medical-chatbot-ppt.pdf        # Project summary presentation
â””â”€â”€ README.md                      # This project documentation

## ðŸš€ Getting Started

### Install Dependencies

Using **Pipenv**:

```bash
pipenv install
pipenv shell



## ðŸ“¥ Create the Vector Store

Add your PDFs to the `/data` folder, then run:

```bash
python create_memory_for_llm.py

